# Multi-AI Setup Guide

TermInA supports multiple AI providers you can configure and switch between. This guide covers how to set up each one.

## ğŸ¤– Supported AI providers

### 1) Google Gemini (recommended)
- Fast and free (with limits)
- Multimodal (text, images, code)
- Great for general use

### 2) OpenAI (GPT)
- Excellent quality
- Advanced models (GPT-4, GPT-4o)
- Paid

### 3) LM Studio (local)
- Fully private
- No cost after setup
- Requires stronger hardware

### 4) Ollama (local)
- Fully private and open source
- Easy to install and configure
- Optimized models for many tasks
- No cost after setup

---

## ğŸ“ Step-by-step configuration

### ğŸ”® Google Gemini

#### 1) Get an API key
1) Go to Google AI Studio: https://makersuite.google.com/
2) Sign in
3) Create/select a project
4) Open â€œAPI Keysâ€
5) Click â€œCreate API Keyâ€
6) Copy the key (e.g., `AIzaSy...`)

#### 2) Configure TermInA
1) Open Settings (âŒ˜+,)
2) Open Artificial Intelligence
3) Choose â€œGoogle Geminiâ€
4) Paste the API key
5) Pick a model:
   - Gemini 2.5 Flash â€” fast, great for general tasks
   - Gemini Pro â€” more powerful for complex tasks
6) Click â€œTest Connectionâ€
7) Save

#### 3) Limits and costs (typical)
- Free: ~15 req/min, ~1M tokens/month
- Paid: see latest Google pricing

---

### ğŸ§  OpenAI (ChatGPT)

#### 1) Get an API key
1) https://platform.openai.com/
2) Sign up / sign in
3) Add a payment method
4) Create a new API key
5) Copy it (format: `sk-...`)

#### 2) Configure TermInA
1) Settings â†’ AI â†’ choose â€œOpenAIâ€
2) Paste the API key
3) Choose a model:
   - GPT-3.5 Turbo â€” cheaper, decent quality
   - GPT-4 â€” higher quality, higher cost
   - GPT-4 Turbo â€” optimized GPT-4
   - GPT-4o â€” latest, faster
4) Test connection
5) Save

#### 3) Costs (typical)
- See OpenAI pricing for up-to-date rates

---

### ğŸ  LM Studio (local)

#### 1) Install LM Studio
https://lmstudio.ai/

#### 2) Download a model
Use Search in LM Studio, e.g. Llama 2 7B, Code Llama 7B, Mistral 7B, Phi-3 Mini

#### 3) Start local server
- Port: 1234 (default)
- Context: 4096+
- GPU Layers: as supported
Click Start Server; verify â€œServer is running on http://localhost:1234â€.

#### 4) Configure TermInA
- Settings â†’ AI â†’ â€œLM Studio (Local)â€
- Endpoint: `http://localhost:1234/v1`
- Model name: e.g., `llama-2-7b-chat`
- API Key: `lm-studio` (or blank)
- Test connection and Save

#### 5) Hardware
- Minimum: 8GB RAM, modern CPU
- Recommended: 16GB+ RAM, dedicated GPU
- Optimal: 32GB+ RAM, NVIDIA 8GB+ VRAM

---

### ğŸ¦™ Ollama (local)

See dedicated guides:
- docs/OLLAMA_SETUP.md â€” setup
- docs/OLLAMA_COMPATIBILITY.md â€” troubleshooting

---

## ğŸ”„ Switching providers

### Quick switch
1) Open Settings (âŒ˜+,)
2) AI â†’ change â€œAI Providerâ€
3) Save
4) The app switches immediately

### Which provider when
- Gemini: everyday use, general questions
- OpenAI: complex tasks, deep analysis
- LM Studio: privacy, offline, experiments
- Ollama: privacy, easy setup, optimized models

---

## ğŸ§ª Testing

Each provider has a â€œTest Connectionâ€ button that:
1) Verifies connectivity
2) Tests authentication
3) Confirms the model responds
4) Shows configuration errors

### Common troubleshooting

Gemini
- 403 Forbidden â€” invalid API key
- 429 Too Many Requests â€” rate limit
- 400 Bad Request â€” check payload shape

OpenAI
- 401 Unauthorized â€” invalid/expired key
- 429 Rate limit â€” too many requests
- 402 Payment Required â€” set up billing

LM Studio
- Connection failed â€” server not running
- 404 Not Found â€” wrong URL
- 500 Internal Error â€” model not loaded

Ollama
- Connection failed â€” Ollama not running
- 404 Not Found â€” wrong URL
- 500 Internal Error â€” model missing/corrupted
- Model not found â€” ensure itâ€™s pulled (`ollama list`)

---

## ğŸ’¡ Advanced tips

```bash
# Quick sanity tests
ai "say only: ok"
execute "create a file named testfile.txt"
```

### Multiple configurations
Switch providers based on needs:
- Gemini: quick, frequent queries
- OpenAI: complex analysis
- LM Studio: privacy and control
- Ollama: privacy and optimized local models

### Backup configuration
Settings live in `~/.termina/config.json`:
```bash
# Backup settings
cp ~/.termina/config.json ~/.termina/config.backup.json
```

### Cost monitoring
- Gemini: Google Cloud Console
- OpenAI: https://platform.openai.com/usage
- LM Studio: free after setup
- Ollama: free after setup

---

## ğŸš¨ Security notes

1) Never share API keys
2) Use environment variables in deployments
3) Monitor usage to avoid surprises
4) LM Studio and Ollama are the most private (all local)
5) Revoke keys if compromised
6) Ollama offers maximum local control

---

## ğŸ“ Support

If you run into issues:
1) Check TermInA logs
2) Verify internet connection (for cloud)
3) Use the Test Connection button
4) Consult the providerâ€™s docs
5) Open a GitHub issue

Enjoy exploring TermInAâ€™s AI! ğŸš€
